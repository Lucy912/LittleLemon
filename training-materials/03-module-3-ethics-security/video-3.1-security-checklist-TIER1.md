# Module 3, Video 1: What NOT to Put in AI
## Tier 1 Quick Production Version

**Length:** 7 minutes
**Deliverable:** AI Security Checklist (1-page reference card)
**Production Time:** 2-3 hours
**Note:** Critical safety content - prevents major risks before they happen

---

## Video Outline (Talking Points)

### [0:00-0:15] HOOK
"Before we go further, we need to talk about what could get you fired, sued, or fined. Here's what you absolutely must never put in AI."

**Visual:** Red warning symbols with examples of sensitive data types

---

### [0:15-0:45] WHY THIS MATTERS (Stakes)

**The reality:**
- ChatGPT/Claude/Gemini are NOT private vaults
- Your data trains their models (some exceptions apply)
- Data breaches happen (Samsung, JP Morgan incidents)
- GDPR fines reach â‚¬20M or 4% of global revenue
- One leak can end careers, damage companies, violate laws

**Recent real incidents:**
- **Samsung (2023):** Engineers pasted proprietary code into ChatGPT â†’ source code leaked
- **Law firms:** Lawyers cited fake cases generated by AI â†’ sanctions, reputation damage
- **Healthcare:** Patient data accidentally shared â†’ HIPAA violations, lawsuits

**This isn't theoretical. This is happening right now.**

**Good news:** Easy to avoid if you know the rules.

---

### [0:45-2:00] THE NEVER LIST (5 Categories)

**NEVER put these 5 things in AI:**

**1. Personal Identifiable Information (PII)**
âŒ Names, addresses, phone numbers, email addresses
âŒ Social security numbers, passport numbers, ID numbers
âŒ Dates of birth, medical records, financial information
âŒ Photos of people, biometric data
âŒ Customer lists with contact details

**Why:** GDPR, CCPA, and privacy laws prohibit sharing without consent.
**Example violation:** "Draft email to john.smith@company.com about his performance issues" â†’ You just shared employee PII.

**2. Proprietary & Confidential Information**
âŒ Source code, algorithms, trade secrets
âŒ Unreleased product plans, pricing strategies
âŒ Financial data (before public disclosure)
âŒ Customer contracts, NDAs, legal agreements
âŒ Internal processes that create competitive advantage

**Why:** Competitors could access it, NDA violations, loss of competitive edge.
**Example violation:** "Review this code for our authentication system" â†’ You exposed security architecture.

**3. Credentials & Access Information**
âŒ Passwords, API keys, tokens
âŒ Database connection strings
âŒ SSH keys, certificates
âŒ Login credentials of any kind
âŒ Security questions/answers

**Why:** Direct path to breach, immediate security risk.
**Example violation:** "Help me debug this code [pastes API key]" â†’ Your API key is now compromised.

**4. Sensitive Business Data**
âŒ Pending deals, M&A information
âŒ Unannounced layoffs, reorgs
âŒ Legal disputes, investigations
âŒ Salary information, compensation data
âŒ Performance reviews with names

**Why:** Insider trading implications, employee relations, legal liability.
**Example violation:** "Draft communication about upcoming 20% layoff" â†’ Leak risk destroys trust, legal issues.

**5. Anything You Don't Have Rights To Share**
âŒ Client data (unless approved in contract)
âŒ Partner information under NDA
âŒ Third-party copyrighted material
âŒ Data from other companies
âŒ Personal data of colleagues without consent

**Why:** Contract violations, copyright infringement, trust destruction.
**Example violation:** "Analyze this customer data from ClientCo" â†’ NDA violation, contract breach.

---

### [2:00-3:15] THE ANONYMIZATION STRATEGY

**You CAN use AI for sensitive topics IF you anonymize properly.**

**The 3-step anonymization process:**

**Step 1: Remove all identifiers**
- Replace names with: Company A, Person 1, Client X
- Remove locations: "A major European city" not "Amsterdam"
- Remove dates: "Q4" not "November 15"
- Remove specific numbers: "~â‚¬50K" not "â‚¬47,326"
- Remove unique details that could identify

**Step 2: Generalize context**
- "A B2B SaaS company" not "A project management tool"
- "A team member" not "Senior engineer on payments team"
- "A client in finance" not "Deutsche Bank"

**Step 3: Test the anonymization**
- Ask: Could someone identify the person/company from this?
- If yes â†’ anonymize more
- If no â†’ safe to proceed

**EXAMPLE: Performance Review Feedback**

âŒ **WRONG (Identifiable):**
"Help me write a performance review for Sarah Johnson, senior developer on the payments team at Amsterdam office. She's been late to meetings and her last 3 PRs had bugs..."

âœ… **RIGHT (Anonymized):**
"Help me write a performance review for a senior developer. Areas to address: Punctuality in team meetings could improve, recent code submissions needed additional review cycles. How do I frame this constructively while being clear about expectations?"

**What changed:**
- Name removed
- Specific role/team generalized
- Location removed
- Context preserved (feedback still useful)
- No way to identify the actual person

**You got the help you needed without compromising privacy.**

---

### [3:15-4:30] SAFE ALTERNATIVES (What TO Do Instead)

**"But I need help with sensitive work. What do I do?"**

**Here are 5 safe alternatives:**

**Alternative 1: Use Enterprise AI with data controls**
- ChatGPT Enterprise (data not used for training)
- Claude Enterprise (data privacy guarantees)
- Azure OpenAI (your private instance)
- Google Vertex AI (controlled environment)
- **Cost:** Higher, but protects sensitive data
- **When:** Your company handles regulated data

**Alternative 2: Local/On-Premise AI**
- Self-hosted LLMs (Llama, Mistral on your servers)
- No data leaves your infrastructure
- **Cost:** Technical setup required
- **When:** Maximum security needed (healthcare, finance, defense)

**Alternative 3: Anonymization (as shown above)**
- Remove PII, keep structure
- Generalize specifics
- **Cost:** Free, just takes thought
- **When:** Need help with process/structure, not specific data

**Alternative 4: Work with templates/examples, not real data**
- Use fictional examples
- "Here's a template customer contract..." (made up)
- Get the framework, apply to real data separately
- **Cost:** Free
- **When:** Learning how to do something new

**Alternative 5: Don't use AI for this task**
- Some things shouldn't involve AI
- Consult lawyer, not AI, for legal questions
- Consult security expert, not AI, for security architecture
- Consult doctor, not AI, for medical decisions
- **When:** Stakes are too high, expertise required

**Decision framework:**
```
Is the data sensitive?
  â†’ YES: Is it anonymizable?
      â†’ YES: Anonymize and proceed
      â†’ NO: Don't use public AI
  â†’ NO: Proceed with public AI
```

---

### [4:30-5:30] COMMON MISTAKES & HOW TO CATCH THEM

**Mistake 1: "I'll just use it once"**
âŒ Thinking: One time won't matter
âœ… Reality: That's when leaks happen
ğŸ›¡ï¸ Fix: Treat every prompt as potentially public

**Mistake 2: "My data isn't that interesting"**
âŒ Thinking: No one cares about my work
âœ… Reality: Aggregated data is valuable, regulators don't care if it's "interesting"
ğŸ›¡ï¸ Fix: Follow rules regardless of perceived importance

**Mistake 3: "I trust this AI company"**
âŒ Thinking: Big tech companies are secure
âœ… Reality: Even best companies have breaches (see: every major breach ever)
ğŸ›¡ï¸ Fix: Trust, but verify. Follow security protocols.

**Mistake 4: "I'll be careful"**
âŒ Thinking: I'll remember what's sensitive
âœ… Reality: Under deadline pressure, mistakes happen
ğŸ›¡ï¸ Fix: Use a checklist before every prompt (deliverable below)

**Mistake 5: "My company doesn't have a policy yet"**
âŒ Thinking: No policy means no rules
âœ… Reality: Laws still apply, common sense still applies
ğŸ›¡ï¸ Fix: Follow this checklist until official policy exists

**The pre-prompt checklist (memorize this):**

Before hitting "Send" on any AI prompt, ask:
1. â˜ Does this contain anyone's name? â†’ Remove or anonymize
2. â˜ Could this identify a specific person/company? â†’ Generalize
3. â˜ Would I be comfortable if this appeared on the front page of a newspaper? â†’ If no, don't send
4. â˜ Is this under NDA or confidential? â†’ Don't send or use enterprise AI
5. â˜ Does this contain passwords, keys, or credentials? â†’ Remove

**If you answered YES to questions 1-5, you need to edit or not send.**

---

### [5:30-6:15] YOUR COMPANY'S AI POLICY

**Does your company have an AI policy?**

**If YES:**
- Read it (seriously, actually read it)
- Follow it (even if it feels restrictive)
- Ask questions if unclear
- Suggest improvements if outdated

**If NO:**
- Follow this checklist until they create one
- Consider proposing a policy (Video 3.3 will help)
- Document your safe usage practices
- Be the responsible example

**What a good AI policy includes:**
1. What tools are approved (ChatGPT, Claude, etc.)
2. What data can/cannot be shared
3. How to anonymize data
4. When to use enterprise vs free tools
5. Who to ask when unsure
6. What happens if you violate the policy

**If you're in a regulated industry (healthcare, finance, legal):**
- Policies are often stricter
- Enterprise/local AI is usually required
- Compliance teams should be involved
- When in doubt, ask before using

---

### [6:15-7:00] CHALLENGE & WRAP

**Your challenge:**

**Step 1: Audit your last 10 AI prompts**
- Go through your ChatGPT/Claude history
- Check: Did I share anything from the NEVER list?
- If yes: Delete those conversations, change exposed credentials
- Learn what mistakes you're prone to

**Step 2: Make the pre-prompt checklist a habit**
- Print the checklist (in deliverable below)
- Put it next to your computer
- Check it before every prompt this week
- It will become automatic

**Step 3: Share with your team**
- Most people don't know these risks
- Share this video or the security checklist
- Prevent disasters before they happen
- Build a culture of responsible AI use

**Download:** AI Security Checklist (printable 1-page reference card)

**Next video:** AI Bias & Fact-Checking (how to verify AI outputs, catch hallucinations, and avoid embarrassing mistakes)

**Remember:** The best AI users aren't the ones who use it the most. They're the ones who use it safely and responsibly.

---

## Deliverable: AI Security Checklist

### Content to Create (1-page PDF, printable reference card):

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AI SECURITY CHECKLIST
What NOT to Put in AI
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Print this and keep it at your desk.
Check before EVERY prompt.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
THE NEVER LIST - 5 Categories
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ 1. PERSONAL IDENTIFIABLE INFORMATION (PII)
   â–¡ Names, addresses, phone numbers, emails
   â–¡ Social security numbers, ID numbers
   â–¡ Dates of birth, medical records
   â–¡ Financial information, account numbers
   â–¡ Photos of people, biometric data

âŒ 2. PROPRIETARY & CONFIDENTIAL INFO
   â–¡ Source code, algorithms, trade secrets
   â–¡ Unreleased product plans, pricing strategies
   â–¡ Financial data (before public disclosure)
   â–¡ Customer contracts, NDAs
   â–¡ Internal processes that create competitive advantage

âŒ 3. CREDENTIALS & ACCESS INFORMATION
   â–¡ Passwords, API keys, tokens
   â–¡ Database connection strings
   â–¡ SSH keys, certificates
   â–¡ Login credentials of any kind
   â–¡ Security questions/answers

âŒ 4. SENSITIVE BUSINESS DATA
   â–¡ Pending deals, M&A information
   â–¡ Unannounced layoffs, reorgs
   â–¡ Legal disputes, investigations
   â–¡ Salary information, compensation data
   â–¡ Performance reviews with names

âŒ 5. ANYTHING YOU DON'T HAVE RIGHTS TO SHARE
   â–¡ Client data (unless approved)
   â–¡ Partner information under NDA
   â–¡ Third-party copyrighted material
   â–¡ Data from other companies
   â–¡ Personal data of colleagues without consent

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PRE-PROMPT CHECKLIST
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Before hitting "Send", verify:

â˜ 1. Does this contain anyone's name?
     â†’ If YES: Remove or anonymize

â˜ 2. Could this identify a specific person/company?
     â†’ If YES: Generalize

â˜ 3. Would I be comfortable if this appeared publicly?
     â†’ If NO: Don't send

â˜ 4. Is this under NDA or confidential?
     â†’ If YES: Don't send (or use enterprise AI)

â˜ 5. Does this contain passwords/keys/credentials?
     â†’ If YES: Remove immediately

If you can't answer "Safe" to all 5, STOP and revise.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ANONYMIZATION GUIDE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You CAN get help with sensitive topics IF anonymized properly.

âœ… THE 3-STEP PROCESS:

STEP 1: Remove all identifiers
â€¢ Names â†’ "Person A", "Company X", "Client 1"
â€¢ Locations â†’ "A major city", "Northern Europe"
â€¢ Dates â†’ "Q3", "Last month" (not specific dates)
â€¢ Numbers â†’ "~â‚¬50K", "Mid-six figures" (approximate)
â€¢ Unique details â†’ Generalize anything distinctive

STEP 2: Generalize context
â€¢ "A B2B SaaS company" not "Salesforce competitor"
â€¢ "A team member" not "Senior engineer on Platform team"
â€¢ "A client in finance" not "A global investment bank"
â€¢ Keep just enough context for useful advice

STEP 3: Test the anonymization
â€¢ Ask: Could someone identify the person/company?
â€¢ If YES â†’ anonymize more
â€¢ If NO â†’ safe to proceed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXAMPLE: Before & After
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ WRONG (Identifiable):
"Help me write a review for Sarah Johnson, senior developer in
Amsterdam. Her last 3 PRs had bugs..."

âœ… RIGHT (Anonymized):
"Help me write a performance review for a senior developer. Area
to address: Recent code submissions needed additional review
cycles. How do I frame this constructively?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SAFE ALTERNATIVES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

When you CAN'T use public AI:

âœ… Option 1: Enterprise AI with data controls
   â†’ ChatGPT Enterprise, Claude Enterprise, Azure OpenAI
   â†’ Data not used for training
   â†’ Cost: Higher, but protects sensitive data

âœ… Option 2: Local/On-premise AI
   â†’ Self-hosted LLMs (Llama, Mistral)
   â†’ No data leaves your infrastructure
   â†’ Cost: Technical setup required

âœ… Option 3: Anonymization (see above)
   â†’ Remove PII, keep structure
   â†’ Cost: Free, just takes thought

âœ… Option 4: Work with templates/examples
   â†’ Use fictional data
   â†’ Get framework, apply to real data separately
   â†’ Cost: Free

âœ… Option 5: Don't use AI for this task
   â†’ Some things shouldn't involve AI
   â†’ Consult expert instead (lawyer, doctor, security specialist)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DECISION FLOWCHART
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Is the data sensitive?
â”œâ”€ NO â†’ âœ… Proceed with public AI
â””â”€ YES â†’ Is it anonymizable?
    â”œâ”€ YES â†’ âœ… Anonymize properly, then proceed
    â””â”€ NO â†’ â›” DON'T use public AI
             Use enterprise AI, local AI, or don't use AI

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
REAL INCIDENTS (Learn from Others' Mistakes)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”´ Samsung (2023)
   â†’ Engineers pasted proprietary code into ChatGPT
   â†’ Result: Source code exposed, company-wide ban

ğŸ”´ Law Firms (2023)
   â†’ Lawyers cited AI-generated fake cases
   â†’ Result: Sanctions, reputation damage

ğŸ”´ Healthcare Providers (2023)
   â†’ Patient data accidentally shared with AI
   â†’ Result: HIPAA violations, lawsuits, fines

Don't be the next cautionary tale.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IF YOU MAKE A MISTAKE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Shared something you shouldn't have?

âš¡ IMMEDIATE ACTIONS:
1. Delete the conversation in AI tool
2. Change any exposed credentials immediately
3. Notify your security team/manager
4. Document what happened (for incident response)
5. Check if legal/compliance needs to be notified

â° Speed matters. Act within minutes, not days.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMPANY POLICY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â˜ My company HAS an AI policy
   â†’ Read it, follow it, ask questions if unclear

â˜ My company DOESN'T have an AI policy (yet)
   â†’ Follow this checklist
   â†’ Use common sense
   â†’ Laws still apply
   â†’ Consider proposing a policy (see Video 3.3)

â˜ I work in regulated industry (healthcare, finance, legal)
   â†’ Extra caution required
   â†’ Enterprise/local AI usually mandatory
   â†’ When in doubt, ask compliance team

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WEEKLY AI SECURITY AUDIT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Every Friday, spend 5 minutes:

â˜ Review my AI prompts from this week
â˜ Check: Did I follow the security checklist?
â˜ Identify any close calls or mistakes
â˜ Adjust my habits based on what I learned
â˜ Share any insights with my team

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EMERGENCY CONTACTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Fill in for your organization:

Security team: _____________________________________
Manager: ___________________________________________
Compliance/Legal: __________________________________
IT help desk: ______________________________________

Know who to contact BEFORE you need them.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KEY REMINDERS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… When in doubt, anonymize or don't send
âœ… Treat every prompt as potentially public
âœ… "I'll just use it once" is how leaks happen
âœ… No policy â‰  no rules (laws still apply)
âœ… The pre-prompt checklist saves careers

The best AI users aren't the ones who use it the most.
They're the ones who use it safely and responsibly.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š NEXT: Video 3.2 - AI Bias & Fact-Checking
Learn how to verify AI outputs and catch hallucinations

Created by Lucy's AI Training | lucyworks.com
```

---

## ChatGPT Examples (Prepare These)

**Example 1: Wrong Way (Identifiable)**
- Show prompt with PII included
- Explain what's wrong
- Show how it could lead to breach/violation

**Example 2: Right Way (Anonymized)**
- Take same scenario
- Show properly anonymized version
- Run it and show you still get useful help

**Example 3: Real Incident Walkthrough**
- Detail the Samsung case (engineers pasting code)
- Show how simple it was to make the mistake
- Show the consequences (company-wide ban)

**Example 4: Pre-Prompt Checklist Demo**
- Show a risky prompt
- Go through the 5 checklist questions
- Show how checklist catches the problem before sending

---

## Production Notes

### Recording Tips:
- Serious tone (this is safety content)
- Use real incident examples (Samsung, law firms)
- Show actual bad prompts (blurred for privacy) vs good ones
- Emphasize this isn't fear-mongering, it's practical protection

### Visual Elements:
- Red warning symbols for NEVER list items
- Before/after comparisons (identifiable vs anonymized)
- Flowchart for decision-making
- Checklist visual (printable-looking)

### Editing Focus:
- Clear categorization (5 NEVER categories)
- Highlight key warnings
- Show checklist multiple times (reinforce)
- End with empowerment, not fear

### Engagement Hooks:
- "Pause and check your last 10 prompts"
- "Print this checklist and put it at your desk"
- "Share this with your team to prevent disasters"

---

## Key Messages

1. **Not fear-mongering, practical protection:** These risks are real, but avoidable
2. **Anonymization enables safe usage:** You CAN get help with sensitive topics
3. **Checklist makes it automatic:** Build the habit, prevent mistakes
4. **Responsibility matters:** Protect yourself, your company, your customers

---

**PRODUCTION TARGET: 2-3 hours**
- Prep: 30 min (research real incidents, prepare examples)
- Record: 60 min (serious content, clear delivery)
- Edit: 30 min (emphasize key warnings)
- Deliverable (security checklist): 45 min (1-page printable reference card)

**OUTCOME: Students understand data security risks and have practical checklist to prevent violations**
